{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Algorithm From Scratch"
      ],
      "metadata": {
        "id": "KxE5o2bNFf60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree algorithm is one of the most popular and practical machine learningtechnique for both classification and regression. Decision trees also provide the foundation for more advanced ensemble methods such as bagging, random forests and gradient boosting.\n",
        "\n",
        "To make implementation more clear and well-organized, the following would be several parts:\n",
        "\n",
        "\n",
        "*   calculate impurity with Gini index and entropy\n",
        "*   choose proper splits\n",
        "*   build the tree\n",
        "*   make a prediction\n",
        "\n",
        "and final part is to put in practice."
      ],
      "metadata": {
        "id": "FqS8ZypuFhjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification with Gini Index"
      ],
      "metadata": {
        "id": "q6qjHRgkMQLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gini Index\n",
        "\n",
        "The Gini index is the most widely used cost function in decision trees. This index calculates the amount of probability that a specific characteristic will be classified incorrectly when it is randomly selected.\n",
        "\n",
        "This is an index that ranges from 0 (a pure cut) to 0.5 (a completely pure cut that divides the data equally). The Gini index is calculated as follows:\\\n",
        "*$Gini = 1-\\sum^{n}_{i=1}(P_i)^2$* \\\n",
        "where *$P_i$* is the probability of having the assigned class or value.\n",
        "\n",
        "According to the formula, the code would be:"
      ],
      "metadata": {
        "id": "qyBGJeufMat9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def gini(data):\n",
        "  # the input of the function would be labels of the data and the data itself.\n",
        "    data_label = data.iloc[:, -1] # get the label\n",
        "    label_num = data_label.value_counts() # count the number of classes and the count within the class\n",
        "    res = 0 # create a variable to recieve the probability\n",
        "    for k in label_num.keys():\n",
        "      # The function in second row would return a dictionary\n",
        "      # for loop is to get the probability of each class\n",
        "        p_k = label_num[k]/len(data_label)\n",
        "        res += p_k ** 2 \n",
        "    return 1 - res"
      ],
      "metadata": {
        "id": "ndoMIopTNhXn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the Gini index of each feature value to find the optimal split point\n",
        "def gini_index(data, a):\n",
        "  # the input: x -- the data itself; a -- the name of the feature\n",
        "    feature_class = data[a].value_counts() # same for the previous function; to get the count within the feature_class\n",
        "    res = [] # create a empty list to get the result\n",
        "    for feature in feature_class.keys(): # the loop for each feature_class\n",
        "        weight = feature_class[feature]/len(data) # return the weight for each feature_class\n",
        "        gini_value = gini(data.loc[data[a] == feature]) # calculate Gini index by defined function\n",
        "        res.append([feature, weight * gini_value]) # append the list with the values\n",
        "    res = sorted(res, key = lambda x: x[-1])\n",
        "    return res[0]"
      ],
      "metadata": {
        "id": "Y1H-MRsuZw7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to obtain the class with most labeled data\n",
        "def get_most_label(data):\n",
        "    data_label = data.iloc[:,-1] # to get the label\n",
        "    label_sort = data_label.value_counts(sort=True) # sort the label by the count within classes\n",
        "    return label_sort.keys()[0]"
      ],
      "metadata": {
        "id": "nhUUt1YQcGuv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to pick the best feature which is with lowest Gini index\n",
        "def get_best_feature(data):\n",
        "    features = data\n",
        "    res = {} # create a empty list\n",
        "    for a in features:\n",
        "        temp = gini_index(data, a) #temp is a list which is like [feature_value, gini]\n",
        "        res[a] = temp\n",
        "    res = sorted(res.items(),key=lambda x:x[1][1])\n",
        "    return res[0][0], res[0][1][0]"
      ],
      "metadata": {
        "id": "BXJx-uFWc3Gy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_exist_feature(data, best_feature, value, type):\n",
        "    attr = pd.unique(data[best_feature]) # the array that has all values of feature\n",
        "    if type == 1: # split by using feature==value\n",
        "        new_data = [[value], data.loc[data[best_feature] == value]]\n",
        "    else:\n",
        "        new_data = [attr, data.loc[data[best_feature] != value]]\n",
        "    new_data[1] = new_data[1].drop([best_feature], axis=1) # remove the feature\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "pIIqnHjMds_5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to build the decision tree\n",
        "def create_tree(data):\n",
        "    data_label = data.iloc[:,-1]\n",
        "    if len(data_label.value_counts()) == 1: # only one class\n",
        "        return data_label.values[0]\n",
        "    if all(len(data[i].value_counts()) == 1 for i in data.iloc[:,:-1].columns): # if the feature of all data is same\n",
        "        return get_most_label(data) # take the most labeled one as result\n",
        "    best_feature, best_feature_value = get_best_feature(data) # get the optimal split point based on diff gini index\n",
        "    Tree = {best_feature:{}} # store the tree with dict\n",
        "\n",
        "    Tree[best_feature][best_feature_value] = create_tree(drop_exist_feature(data, best_feature, best_feature_value, 1)[1])\n",
        "    Tree[best_feature]['Others'] = create_tree(drop_exist_feature(data, best_feature, best_feature_value, 2)[1])\n",
        "    return Tree"
      ],
      "metadata": {
        "id": "rp9kXwi0e7z0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(Tree , test_data):\n",
        "    first_feature = list(Tree.keys())[0] # to get the first feature\n",
        "    second_dict = Tree[first_feature] # dict after the first feature\n",
        "    input_first = test_data.get(first_feature) # predict the first feature value of input\n",
        "    input_value = second_dict[input_first] if input_first == first_feature else second_dict['Others'] # predict the dictionary corresponding to the input\n",
        "    if isinstance(input_value , dict): # check if the branch is dict?\n",
        "        class_label = predict(input_value, test_data)\n",
        "    else:\n",
        "        class_label = input_value\n",
        "    return class_label"
      ],
      "metadata": {
        "id": "F7yjj6YGfvob"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from math import log\n",
        "\n",
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=666666)"
      ],
      "metadata": {
        "id": "dmzEUFpXgQpm"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([pd.DataFrame(x_train), pd.DataFrame(y_train)], axis=1)\n",
        "data.columns = ['a','b','c','d', 'label']\n",
        "decision_Tree = create_tree(data)\n"
      ],
      "metadata": {
        "id": "bvx3MkPQUFsB"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict(Tree , test_data):\n",
        "first_feature = list(decision_Tree.keys())[0] # to get the first feature\n",
        "second_dict = decision_Tree[first_feature] # dict after the first feature\n",
        "input_first = x_test.loc[22].get(first_feature) # predict the first feature value of input\n",
        "input_value = second_dict[input_first] if input_first == first_feature else second_dict['Others'] # predict the dictionary corresponding to the input\n",
        "if isinstance(input_value , dict): # check if the branch is dict?\n",
        "        class_label = predict(input_value, x_test.loc[22])\n",
        "else:\n",
        "        class_label = input_value\n",
        "print(class_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYvjI64NEjYk",
        "outputId": "d2fb71de-46c3-464f-9a4a-b63b60a76641"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.DataFrame(x_test)\n",
        "x_test.columns = ['a','b','c','d']\n",
        "# print(x_test)\n",
        "y_pred = []\n",
        "for i in range(x_test.shape[0]):\n",
        "  result = predict(decision_Tree,x_test.loc[i])\n",
        "  y_pred.append(result)"
      ],
      "metadata": {
        "id": "47X7KUI4wbwP"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification with entropy"
      ],
      "metadata": {
        "id": "FHISxiJRrkVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entropy\n",
        "\n",
        "Entropy can be used to scale the uncertainty of random variable. The greater random variable's entropy is, the more uncertainty it has.\\\n",
        "$Entropy=-\\sum^{n}_{i=1}p_ilog(p_i)$,\\\n",
        "where $p_i$ is the probability of the class or value."
      ],
      "metadata": {
        "id": "TSTFMPIRr5Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(label):\n",
        "    counter = Counter(label) # Count the number of occurrences of different elements and the return value can be generated as a dictionary\n",
        "    ent = 0\n",
        "    for num in counter.values():\n",
        "        p = num / len(label)\n",
        "        ent += -p * log(p)\n",
        "    return ent"
      ],
      "metadata": {
        "id": "D2ErVhJmtULc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to split the data\n",
        "def split(x_data, y_label, dimension, value):\n",
        "  # the input would be: x_data--data with features; y_label--labels; dimension--the index of the feature; value--the value of the feature\n",
        "    index_left = (x_data[:,dimension] <= value)\n",
        "    index_right = (x_data[:,dimension] > value)\n",
        "    return x_data[index_left], x_data[index_right], y_label[index_left], y_label[index_right]"
      ],
      "metadata": {
        "id": "iPjOefZMtdAC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to traverse all the dimensions, looking for the right number to split, to find the feature and the number to minimize entropy\n",
        "def one_split(x_data, y_label):\n",
        "    \n",
        "    best_entropy = float('inf')\n",
        "    best_dimension = -1\n",
        "    best_value = -1\n",
        "    \n",
        "    for d in range(x_data.shape[1]):\n",
        "        sorted_index = np.argsort(x_data[:, d])\n",
        "        for i in range(1,len(x_data)):\n",
        "            if x_data[sorted_index[i], d] != x_data[sorted_index[i - 1], d]:\n",
        "                value = (x_data[sorted_index[i], d] + x_data[sorted_index[i-1], d]) / 2\n",
        "                x_left, x_right, y_left, y_right = split(x_data, y_label, d, value)\n",
        "                \n",
        "                p_left = len(x_left) / len(x_data)\n",
        "                p_right = len(x_right) / len(x_data)\n",
        "                \n",
        "                ent = p_left * entropy(y_left) + p_right * entropy(y_right)\n",
        "                if ent < best_entropy:\n",
        "                    best_entropy = ent\n",
        "                    best_dimension = d\n",
        "                    best_value = value\n",
        "    return best_entropy, best_dimension, best_value"
      ],
      "metadata": {
        "id": "i85umHNQuFro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self,x_data, y_label, dimension, value):\n",
        "        self.x_data = x_data\n",
        "        self.y_label = y_label\n",
        "        self.dimension = dimension\n",
        "        self.value = value\n",
        "        self.left = None\n",
        "        self.right = None"
      ],
      "metadata": {
        "id": "5iY7smxXv1an"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tree(x_data, y_label):\n",
        "    ent, dim, value = one_split(x_data, y_label)\n",
        "    x_left, x_right, y_left, y_right = split(x_data, y_label, dim, value)\n",
        "    node = Node(x_data, y_label, dim, value)\n",
        "    if ent < 0.000000001:\n",
        "      return node\n",
        "    node.left = create_tree(x_left, y_left)\n",
        "    node.right = create_tree(x_right, y_right)\n",
        "    return node"
      ],
      "metadata": {
        "id": "IUGxokR2vJ81"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def travel(x_data, node):\n",
        "    p = node\n",
        "    if x_data[p.dimension] <= p.value and p.left:\n",
        "        pred = travel(x_data, p.left)\n",
        "    elif x_data[p.dimension] > p.value and p.right:\n",
        "        pred = travel(x_data, p.right)\n",
        "    else:\n",
        "        counter = Counter(p.y_label)\n",
        "        pred = counter.most_common(1)[0][0]\n",
        "    return pred"
      ],
      "metadata": {
        "id": "s4q13c9AwSR9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, x_predict):\n",
        "    y_predict = []\n",
        "    for data in x_predict:\n",
        "      y_pred = travel(data, tree)\n",
        "      y_predict.append(y_pred)\n",
        "    return np.array(y_predict)"
      ],
      "metadata": {
        "id": "eUztwP-1yDze"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(tree, x_test, y_test):\n",
        "    y_predict = predict(tree, x_test)\n",
        "    return np.sum(y_predict == y_test) / len(y_predict)"
      ],
      "metadata": {
        "id": "BauxUyKgyg3B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from math import log\n",
        "\n",
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=666666)"
      ],
      "metadata": {
        "id": "gDWJ1_dnw9zj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = create_tree(x_train, y_train)\n",
        "y_pred = predict(tree,x_test)\n",
        "print(y_pred)\n",
        "sc = score(tree, x_test, y_test)\n",
        "print(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWsWMuy5w9Qx",
        "outputId": "43b4b2b7-91cd-4943-d7db-2778b49c5d8c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression model"
      ],
      "metadata": {
        "id": "28-Iib7w2O_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision tree regression model can be interpreted as a set of if-else statements, and it is widely used due to its simplicity, interpretability, and ability to handle nonlinear relationships between the input and target variables."
      ],
      "metadata": {
        "id": "XaUUXsjZ91Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the square error\n",
        "def squaErr(data, result, sequence, parameter, divide):\n",
        "    # input data: data--x, result--y, sequence--for index, divede--index of split point;\n",
        "    \n",
        "    # to pick the data we are going to use\n",
        "    left = []\n",
        "    right = []\n",
        "    for i in sequence:\n",
        "        if data[i,parameter]<divide:\n",
        "            left.append(i)\n",
        "        else:\n",
        "            right.append(i)\n",
        "            \n",
        "    # to calculate the square error on left and right regions\n",
        "    c1 = np.mean(result[left])\n",
        "    err1 = np.sum((result[left]-c1)**2)\n",
        "\n",
        "    c2 = np.mean(result[right])\n",
        "    err2 = np.sum((result[right]-c2)**2)\n",
        "    \n",
        "    return err1+err2"
      ],
      "metadata": {
        "id": "hmmhsaqmEh_m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# traverse all to determine the next split point and value\n",
        "def bestdivide(data,result,sequence):\n",
        "    min_para = 0\n",
        "    sortedValue = np.sort(data[sequence][:,min_para]) # sort the feature/data by the result\n",
        "    min_divide = (sortedValue[0]+sortedValue[1])/2 # start splitting with middle one\n",
        "    err = squaErr(data,result,sequence,min_para,min_divide) # calculate square error by calling defined function\n",
        "\n",
        "    for para in range(data.shape[1]):\n",
        "        # update/generate a set of split point with one feature\n",
        "        sortedValue = np.sort(data[sequence][:,para]) # sort the data corresponding to the dividing point\n",
        "        sliceValue = (sortedValue[1:]+sortedValue[:-1])/2 # split from the middle\n",
        "        for divide in sliceValue:\n",
        "            errNew = squaErr(data,result,sequence,para,divide) # calcalate the squaError\n",
        "            if errNew < err:\n",
        "              # if new error is less, then update\n",
        "                err = errNew\n",
        "                min_para = para\n",
        "                min_divide = divide \n",
        "    return min_para, min_divide, err"
      ],
      "metadata": {
        "id": "izdv7g7vEmnQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need a class defining the tree\n",
        "class RegressionTree:\n",
        "    def __init__(self,sequence):\n",
        "        self.isLeaf = True # if it is a leaf/node\n",
        "        self.left =None\n",
        "        self.right = None\n",
        "        self.output = np.mean(result[sequence])\n",
        "        self.sequence = sequence\n",
        "        self.parameter = None\n",
        "        self.divide = None\n",
        "\t\t\n",
        "    # define the action (grow function) for the tree, grow from current node/leaf\n",
        "    def grow(self, minnum):\n",
        "            if (len(self.sequence)<= minnum):\n",
        "              # minimal number of elements\n",
        "                return\n",
        "            parameter,divide,err = bestdivide(data, result, self.sequence)\n",
        "            left = []\n",
        "            right =[]\n",
        "            for i in self.sequence:\n",
        "                if(data[i,parameter]<divide):\n",
        "                    left.append(i)\n",
        "                else:\n",
        "                    right.append(i)\n",
        "            self.parameter = parameter\n",
        "            self.divide = divide\n",
        "            self.isLeaf = False\n",
        "            self.left = RegressionTree(left)\n",
        "            self.right = RegressionTree(right)"
      ],
      "metadata": {
        "id": "lKxvyuxbEQ2r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updateTree(tree,minNum):\n",
        "    if tree.isLeaf:\n",
        "      tree.grow(minNum)\n",
        "    else:\n",
        "      updateTree(tree.left, minNum)\n",
        "      updateTree(tree.right, minNum)"
      ],
      "metadata": {
        "id": "_dyq3qhxMGXS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data,result,minNum = 1,maxLevel = 5):\n",
        "    # self.data = data\n",
        "    # self.result = result\n",
        "    # minNum = minNum\n",
        "    # self.maxLevel = maxLevel\n",
        "    tree = RegressionTree(range(data.shape[0]))\n",
        "\t\t\n",
        "    # The number of decision tree grows is determined by maxLevel\n",
        "    for i in range(maxLevel):\n",
        "      updateTree(tree, minNum)\n",
        "    return tree"
      ],
      "metadata": {
        "id": "z0kUSKpfLrEW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on single point        \n",
        "def singlePredict(tree, data):\n",
        "  if(tree==None):\n",
        "    return None\n",
        "  tree = tree\n",
        "  while(True):\n",
        "    if(tree.isLeaf):\n",
        "      return tree.output\n",
        "    if(data[tree.parameter]<tree.divide):\n",
        "      tree = tree.left\n",
        "    else:\n",
        "      tree = tree.right"
      ],
      "metadata": {
        "id": "MJ0UK35YNsX9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the data according to the trained model\n",
        "def predict(tree, data):\n",
        "  result = []\n",
        "  if(tree==None):\n",
        "    return None\n",
        "  for i in range (data.shape[0]):\n",
        "    result.append(singlePredict(tree, data[i]))\n",
        "  return result"
      ],
      "metadata": {
        "id": "EzLyaMSrNVos"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn import model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "result = raw_df.values[1::2, 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, result, test_size=0.3, random_state=66666)"
      ],
      "metadata": {
        "id": "2HcExS_KOntR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = train(X_train,y_train,2,10)\n",
        "result1 = predict(tree, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWwTZpQBOp0T",
        "outputId": "67d86638-82a0-4728-8510-aa2dfee861da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the maximum squared error   \n",
        "def err(result, y):\n",
        "    err = (result-y)**2\n",
        "    return err.sum()"
      ],
      "metadata": {
        "id": "Z1eWcJJcErLE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the error trend by traversing the tree from 5 to 15 levels\n",
        "errs =[]\n",
        "for i in range(5,16):\n",
        "    tree = train(X_train,y_train,2,i)\n",
        "    errs.append(err(predict(tree,X_test),y_test))\n",
        "\n",
        "# plot the trend\t\n",
        "plt.plot(range(5,16),errs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "yHsbCbN6SmdO",
        "outputId": "fe01d926-164a-42e6-cac1-fc26184afe7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4794953250>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}