{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Prepare data as dataframe:\n",
    "data = pd.read_csv(\"AB_NYC_2019.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Apply Label Encoding for Categorical Data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Apply label encoding to 'neighbourhood_group' and 'room_type'\n",
    "le=LabelEncoder()\n",
    "data['group_encoded']=le.fit_transform(data['neighbourhood_group'])\n",
    "data['room_type']=le.fit_transform(data['room_type'])\n",
    "\n",
    "# Calculate mean price for each neighborhood_group and neighborhood combination\n",
    "grouped = data.groupby(['neighbourhood_group', 'neighbourhood'])['price'].mean()\n",
    "mapping_dict = grouped.to_dict()\n",
    "\n",
    "# Replace neighborhood column with mean prices\n",
    "data['neighbourhood_encoded'] = data.apply(lambda x: mapping_dict.get((x['neighbourhood_group'], x['neighbourhood']), np.nan), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Calculate recency of last_review based on date-time column in source dataset\n",
    "\n",
    "data['last_review'] = pd.to_datetime(data['last_review'])\n",
    "last_day_of_2019 = pd.Timestamp(year=2019, month=12, day=31)\n",
    "data['recency'] = np.log((last_day_of_2019 - data['last_review']).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Replace neighborhood column with price range\n",
    "grouped_1 = data.groupby(['neighbourhood_group', 'neighbourhood'])['price'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "mapping_dict_1 = grouped_1.to_dict()\n",
    "\n",
    "data['group_range'] = data.apply(lambda x: mapping_dict_1.get((x['neighbourhood_group'], x['neighbourhood']), np.nan), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Remove columns assessed not to affect results\n",
    "new_data=data.drop(['id','host_name','name','neighbourhood_group','neighbourhood','last_review'],axis=1)\n",
    "new_data=new_data[new_data['price']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Select only the numerical columns for normalization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_cols = new_data.select_dtypes(include=['int64','float64']).drop(['room_type', 'price','group_encoded'], axis=1).columns.tolist()\n",
    "# Normalize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "new_data[numerical_cols] = scaler.fit_transform(new_data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Drop columns with na values:\n",
    "new_data['price']=np.log(new_data['price'])\n",
    "new_data = new_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Apply Lasso regularization:\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha_lasso = 10**np.linspace(-3,1,100)\n",
    "lasso = Lasso()\n",
    "coefs_lasso = []\n",
    "\n",
    "for i in alpha_lasso:\n",
    "    lasso.set_params(alpha = i)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs_lasso.append(lasso.coef_)\n",
    "    \n",
    "plt.figure(figsize=(12,10))\n",
    "ax = plt.gca()\n",
    "ax.plot(alpha_lasso, coefs_lasso)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights: scaled coefficients')\n",
    "plt.title('Lasso regression coefficients Vs. alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Set Lasso parameters and sort features by importance\n",
    "lasso = Lasso(alpha=10**(-2))\n",
    "model_lasso = lasso.fit(X_train, y_train)\n",
    "coef = pd.Series(model_lasso.coef_,index=X_train.columns)\n",
    "print(coef[coef != 0].abs().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Display feature importance visually\n",
    "\n",
    "fea = X_train.columns\n",
    "a = pd.DataFrame()\n",
    "a['feature'] = fea\n",
    "a['importance'] = coef.values\n",
    "\n",
    "a = a.sort_values('importance',ascending = False)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(a['feature'],a['importance'])\n",
    "plt.title('the importance features')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Modelling & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Train, Test, Split:\n",
    "feature = coef[coef != 0].index.tolist()\n",
    "dt = new_data[feature]\n",
    "\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dt\n",
    "y = new_data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 666)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Plain Vanila Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import model from libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(max_depth=6,min_samples_leaf=0.12)\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Apply gridsearch to find optimal parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pgrid = {\"max_depth\": [3,4,5,6,7,8,9,10],\n",
    "          \"min_samples_leaf\": [ 0.12,0.14,0.16,0.18,0.20]}\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate r2 Score:\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Import model from libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor(n_estimators=100, bootstrap=True)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply Gridsearch to find optimal parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pgrid = {\"n_estimators\": [100,200,300,400,500]}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate r2 Score:\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2(a): Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import model from libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest2 = RandomForestRegressor(n_estimators=100, bootstrap=True)\n",
    "random_forest2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply Gridsearch to find optimal parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pgrid = {\"n_estimators\": [100,200,300,400,500],\n",
    "         \"max_depth\": [4,5,6,7,8,9,10,11]}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred = random_forest2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate r2 Score:\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. Import model from libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "regressor = ExtraTreesRegressor(n_estimators = 500, bootstrap=True, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply gridsearch to find optimal parameter for max_depth of ExtraTreesRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pgrid = {\"max_depth\": [4, 5, 6, 7, 8, 9, 10, 11, 12]}\n",
    "grid_search = GridSearchCV(ExtraTreesRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate r2 Score:\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model* 5: AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import model from libraries\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_reg = AdaBoostRegressor(n_estimators=100)\n",
    "ada_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply gridsearch to find optimal parameter for max_depth of AdaBoost on n_estimators\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pgrid = {\"n_estimators\": [100,200,300,400,500,600,700]}\n",
    "grid_search = GridSearchCV(AdaBoostRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred = ada_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install catboost\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train model on training data\n",
    "model = cb.CatBoostRegressor(loss_function='RMSE')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply gridsearch to find optimal parameters\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pgrid = {\"max_depth\": [4,5,6,7,8,9,10,11]}\n",
    "grid_search = GridSearchCV(CatBoostRegressor(), param_grid=pgrid, scoring='neg_mean_squared_error', cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute r2_score:\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
